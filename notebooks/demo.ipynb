{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f702a5ea",
   "metadata": {},
   "source": [
    "# Human Behaviour Convergence: Demo Notebook\n",
    "\n",
    "This notebook demonstrates the end-to-end forecasting pipeline using synthetic data.\n",
    "\n",
    "**Contents:**\n",
    "1. Load synthetic data\n",
    "2. Compute convergence metric\n",
    "3. Generate forecasts\n",
    "4. Visualize results\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3.10+\n",
    "- pandas, numpy, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5eef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb6c53",
   "metadata": {},
   "source": [
    "## 1. Load Synthetic Data\n",
    "\n",
    "We'll load the example ground truth and forecast data from the `results/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ground_truth = pd.read_csv('../results/ground_truth.csv')\n",
    "forecasts = pd.read_csv('../results/forecasts.csv')\n",
    "intervals = pd.read_csv('../results/intervals.csv')\n",
    "metrics = pd.read_csv('../results/metrics.csv')\n",
    "\n",
    "print(f\"Ground truth shape: {ground_truth.shape}\")\n",
    "print(f\"Forecasts shape: {forecasts.shape}\")\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df68b1",
   "metadata": {},
   "source": [
    "## 2. Compute Convergence Metric\n",
    "\n",
    "The convergence metric measures how well the forecast aligns with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c66650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ground truth and forecasts\n",
    "merged = ground_truth.merge(forecasts, on=['timestamp', 'location_id'])\n",
    "\n",
    "# Compute absolute error\n",
    "merged['abs_error'] = np.abs(merged['count'] - merged['forecast_mean'])\n",
    "\n",
    "# Compute mean absolute error\n",
    "mae = merged['abs_error'].mean()\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36f176",
   "metadata": {},
   "source": [
    "## 3. Visualize Results\n",
    "\n",
    "Plot ground truth vs forecasts for a single location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3344bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for one location\n",
    "location = 'grid_001'\n",
    "loc_data = merged[merged['location_id'] == location]\n",
    "loc_intervals = intervals[intervals['location_id'] == location]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loc_data['timestamp'], loc_data['count'], 'o-', label='Ground Truth', linewidth=2)\n",
    "plt.plot(loc_data['timestamp'], loc_data['forecast_mean'], 's--', label='Forecast', linewidth=2)\n",
    "plt.fill_between(range(len(loc_intervals)), \n",
    "                 loc_intervals['lower_95'], \n",
    "                 loc_intervals['upper_95'], \n",
    "                 alpha=0.2, label='95% Prediction Interval')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Forecast vs Ground Truth: {location}')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04704edf",
   "metadata": {},
   "source": [
    "## 4. Summary Metrics\n",
    "\n",
    "Display all evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics\n",
    "print(\"=\" * 40)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\" * 40)\n",
    "for _, row in metrics.iterrows():\n",
    "    print(f\"{row['metric'].upper():20s}: {row['value']:.4f}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798f2ee",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Experiment with different forecasting models\n",
    "- Add more locations and time steps\n",
    "- Implement custom convergence metrics\n",
    "- Explore privacy-preserving techniques\n",
    "\n",
    "**Note:** All data in this notebook is synthetic. Real-world data would be aggregated to ≥5 km spatial and ≥24 h temporal resolution to preserve privacy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
