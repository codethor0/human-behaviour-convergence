name: Integrity Gates

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  contract-tests:
    name: Contract Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Run contract tests
        run: |
          pytest tests/test_analytics_contracts.py -v --tb=short
        env:
          HBC_CI_OFFLINE_DATA: "1"

  embed-contract:
    name: Embed Contract Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Run embed contract tests
        run: |
          python3 tests/test_grafana_embeds.py

  metrics-integrity:
    name: Metrics Integrity Gate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Start stack
        run: |
          docker compose up -d --build backend prometheus
          sleep 30
      - name: Wait for services
        run: |
          timeout 60 bash -c 'until curl -fsS http://localhost:8100/health; do sleep 2; done'
          timeout 60 bash -c 'until curl -fsS http://localhost:9090/-/ready; do sleep 2; done'
      - name: Generate forecasts for test regions
        run: |
          python3 << 'PYEOF'
          import requests
          import time
          
          base_url = "http://localhost:8100"
          test_regions = [
              {"region_id": "us_mn", "region_name": "Minnesota"},
              {"region_id": "us_ca", "region_name": "California"},
              {"region_id": "city_nyc", "region_name": "New York City"},
          ]
          
          for region in test_regions:
              payload = {
                  "region_id": region["region_id"],
                  "region_name": region["region_name"],
                  "days_back": 30,
                  "forecast_horizon": 7,
              }
              response = requests.post(
                  f"{base_url}/api/forecast",
                  json=payload,
                  timeout=120,
              )
              response.raise_for_status()
              print(f"✓ Generated forecast for {region['region_id']}")
              time.sleep(2)
          PYEOF
      - name: Wait for Prometheus scrape
        run: sleep 10
      - name: Verify metrics integrity
        run: |
          python3 << 'PYEOF'
          import requests
          import sys
          
          prometheus_url = "http://localhost:9090"
          
          # Check for region=None labels
          metrics_response = requests.get("http://localhost:8100/metrics", timeout=10)
          metrics_text = metrics_response.text
          
          if 'region="None"' in metrics_text or 'region=None' in metrics_text:
              print("❌ FAIL: Found region=None labels in metrics")
              sys.exit(1)
          else:
              print("✓ PASS: No region=None labels")
          
          # Check multi-region metrics
          queries = {
              "behavior_index": 'count(count by(region)(behavior_index))',
              "parent_subindex_value": 'count(count by(region)(parent_subindex_value))',
              "child_subindex_value": 'count(count by(region)(child_subindex_value))',
          }
          
          all_pass = True
          for metric, query in queries.items():
              response = requests.get(
                  f"{prometheus_url}/api/v1/query",
                  params={"query": query},
                  timeout=10,
              )
              response.raise_for_status()
              data = response.json()
              
              if data.get("data", {}).get("result"):
                  count = int(float(data["data"]["result"][0]["value"][1]))
                  if count >= 3:
                      print(f"✓ PASS: {metric} has {count} distinct regions")
                  else:
                      print(f"❌ FAIL: {metric} only has {count} distinct regions (expected >= 3)")
                      all_pass = False
              else:
                  print(f"❌ FAIL: {metric} query returned no results")
                  all_pass = False
          
          if not all_pass:
              print("\nDiagnostics:")
              print("Docker status:")
              import subprocess
              subprocess.run(["docker", "compose", "ps"])
              print("\nBackend logs (tail):")
              subprocess.run(["docker", "compose", "logs", "--tail=50", "backend"])
              print("\nMetrics excerpt:")
              print(metrics_text[:1000])
              sys.exit(1)
          
          print("\n✓ All metrics integrity checks passed")
          PYEOF
      - name: Cleanup
        if: always()
        run: docker compose down -v

  data-quality-lightweight:
    name: Data Quality (CI Mode)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Run data quality checkpoint (CI mode)
        run: |
          HBC_CI_OFFLINE_DATA=1 python3 scripts/run_data_quality_checkpoint.py
        continue-on-error: true
      - name: Check for failures
        run: |
          if grep -q "FAIL:" /tmp/HBC_DATA_QUALITY_REPORT.md 2>/dev/null; then
            echo "❌ Data quality check found FAIL status"
            cat /tmp/HBC_DATA_QUALITY_REPORT.md
            exit 1
          else
            echo "✓ Data quality checks passed (or report not generated)"
          fi
