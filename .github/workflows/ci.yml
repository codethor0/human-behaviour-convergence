# SPDX-License-Identifier: PROPRIETARY
name: CI

on:
  push:
    branches: [main]
    paths-ignore:
      - '.github/**'
  pull_request:
    branches: [main]
    paths-ignore:
      - '.github/**'
  workflow_dispatch: {}

# Cancel in-progress runs for the same workflow on PR updates
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  DISK_CAP_GB: 10
  MAX_LOG_MB: 5
  PYTHON_VERSION: '3.10'
  NODE_VERSION: '20'
  PYTHONPATH: ${{ github.workspace }}
  FAIL_ON_ERROR: 'true'
  STRICT_MODE: 'true'

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  pre-flight-checks:
    name: Pre-Flight Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate Working Directory
        run: |
          echo "=== Validating Working Directory ==="
          if [ "$PWD" != "${{ github.workspace }}" ]; then
            echo "ERROR: Working directory mismatch"
            echo "Expected: ${{ github.workspace }}"
            echo "Actual: $PWD"
            exit 1
          fi
          echo "Working directory: $PWD"

      - name: Validate YAML Syntax
        run: |
          echo "=== Validating YAML Syntax ==="
          python3 << 'PYEOF'
          import yaml
          import os
          import sys

          errors = 0
          workflow_dir = '.github/workflows'

          for filename in os.listdir(workflow_dir):
              if not filename.endswith(('.yml', '.yaml')):
                  continue
              filepath = os.path.join(workflow_dir, filename)
              try:
                  with open(filepath, 'r') as f:
                      yaml.safe_load(f)
                  print(f"PASS: {filename}")
              except yaml.YAMLError as e:
                  print(f"FAIL: {filename} - {e}")
                  errors += 1
              except Exception as e:
                  print(f"FAIL: {filename} - {e}")
                  errors += 1

          if errors > 0:
              sys.exit(1)
          PYEOF

      - name: Validate Required Files
        run: |
          echo "=== Validating Required Files ==="
          MISSING=0
          for file in "requirements.txt" "requirements-dev.txt" "app/backend/requirements.txt" ".python-version" "pyproject.toml"; do
            if [ ! -f "$file" ]; then
              echo "ERROR: Missing required file: $file"
              MISSING=$((MISSING + 1))
            fi
          done
          if [ $MISSING -gt 0 ]; then
            echo "ERROR: Found $MISSING missing required files"
            exit 1
          fi
          echo "All required files exist"

      - name: Validate Required Directories
        run: |
          echo "=== Validating Required Directories ==="
          MISSING=0
          for dir in "app" "app/backend" "tests" ".github/scripts"; do
            if [ ! -d "$dir" ]; then
              echo "ERROR: Missing required directory: $dir"
              MISSING=$((MISSING + 1))
            fi
          done
          if [ $MISSING -gt 0 ]; then
            echo "ERROR: Found $MISSING missing required directories"
            exit 1
          fi
          echo "All required directories exist"

      - name: Validate Python Version File
        run: |
          echo "=== Validating .python-version ==="
          if [ ! -f ".python-version" ]; then
            echo "ERROR: .python-version file not found"
            exit 1
          fi
          PYTHON_VER=$(cat .python-version)
          if [ -z "$PYTHON_VER" ]; then
            echo "ERROR: .python-version is empty"
            exit 1
          fi
          echo "Python version in file: $PYTHON_VER"

      - name: Check for Temporary Files
        run: |
          echo "=== Checking for Temporary Files ==="
          TEMP_FILES=$(find . -type f \( -name "*.tmp" -o -name "*.log" -o -name "*.swp" -o -name ".DS_Store" \) -not -path "./.git/*" -not -path "./node_modules/*" -not -path "./.venv/*" 2>/dev/null | wc -l)
          if [ "$TEMP_FILES" -gt 0 ]; then
            echo "WARNING: Found temporary files (not blocking)"
            find . -type f \( -name "*.tmp" -o -name "*.log" -o -name "*.swp" -o -name ".DS_Store" \) -not -path "./.git/*" -not -path "./node_modules/*" -not -path "./.venv/*" 2>/dev/null | head -5
          fi

      - name: Check for Agent Artifacts and Prompt Files
        run: |
          echo "=== Checking for Agent Artifacts and Prompt Files ==="
          ARTIFACT_PATTERNS=(
            "*master_prompt*"
            "*verify_*.sh"
            "*agent*report*"
            "*MASTER_PROMPT*"
            "*_validation.sh"
            "*_verify.sh"
          )

          # Special patterns that should match .md files
          REPORT_PATTERNS=(
            "*_report.md"
            "*_validation_report.md"
            "*_verify_report.md"
          )

          FOUND_ARTIFACTS=0
          ARTIFACT_LIST=""

          for pattern in "${ARTIFACT_PATTERNS[@]}"; do
            # Exclude virtual environments, build artifacts, and legitimate directories
            MATCHES=$(find . -type f -iname "$pattern" \
              -not -path "./.git/*" \
              -not -path "./node_modules/*" \
              -not -path "./.venv/*" \
              -not -path "./.healthcheck-venv/*" \
              -not -path "./.next/*" \
              -not -path "./playwright-report/*" \
              -not -path "./test-results/*" \
              -not -path "*/__pycache__/*" \
              -not -path "*/site-packages/*" \
              -not -path "./ops/*" \
              2>/dev/null | grep -v "^\./\.github/" | grep -v "^\./docs/" || true)

            if [ -n "$MATCHES" ]; then
              echo "ERROR: Found agent artifact matching pattern '$pattern':"
              echo "$MATCHES" | head -10
              FOUND_ARTIFACTS=$((FOUND_ARTIFACTS + $(echo "$MATCHES" | wc -l)))
              ARTIFACT_LIST="${ARTIFACT_LIST}${MATCHES}"$'\n'
            fi
          done

          # Check report patterns separately (these should match .md files)
          for pattern in "${REPORT_PATTERNS[@]}"; do
            MATCHES=$(find . -type f -iname "$pattern" \
              -not -path "./.git/*" \
              -not -path "./node_modules/*" \
              -not -path "./.venv/*" \
              -not -path "./.healthcheck-venv/*" \
              -not -path "./.next/*" \
              -not -path "./playwright-report/*" \
              -not -path "./test-results/*" \
              -not -path "./ops/*" \
              2>/dev/null | grep -v "^\./\.github/" | grep -v "^\./docs/" || true)

            if [ -n "$MATCHES" ]; then
              echo "ERROR: Found agent artifact matching pattern '$pattern':"
              echo "$MATCHES" | head -10
              FOUND_ARTIFACTS=$((FOUND_ARTIFACTS + $(echo "$MATCHES" | wc -l)))
              ARTIFACT_LIST="${ARTIFACT_LIST}${MATCHES}"$'\n'
            fi
          done

          if [ "$FOUND_ARTIFACTS" -gt 0 ]; then
            echo ""
            echo "FAIL: Found $FOUND_ARTIFACTS agent artifact(s) in repository"
            echo "These files should not be committed. Remove them and update .gitignore if needed."
            echo ""
            echo "Found files:"
            echo "$ARTIFACT_LIST" | sort -u
            exit 1
          else
            echo "PASS: No agent artifacts or prompt files found"
          fi

      - name: Validate Architecture
        run: |
          echo "=== Validating Architecture ==="
          python3 .github/scripts/validate_architecture.py

  build:
    name: build
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Pre-cleanup disk
        run: |
          echo "=== Pre-cleanup Disk Usage ==="
          df -h | head -2
          find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
            app/backend/requirements.txt

      - name: Validate Requirements Files Exist
        run: |
          echo "=== Validating Requirements Files ==="
          for req_file in requirements.txt requirements-dev.txt app/backend/requirements.txt; do
            if [ ! -f "$req_file" ]; then
              echo "ERROR: Missing requirements file: $req_file"
              exit 1
            fi
            echo "Found: $req_file"
          done

      - name: Validate Requirements Syntax
        run: |
          echo "=== Validating Requirements Syntax ==="
          for req_file in requirements.txt requirements-dev.txt app/backend/requirements.txt; do
            if ! python3 -c "import pkg_resources; [pkg_resources.Requirement.parse(line.strip()) for line in open('$req_file') if line.strip() and not line.startswith('#')]" 2>/dev/null; then
              echo "WARNING: $req_file may have syntax issues (continuing)"
            fi
          done

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r app/backend/requirements.txt
          pip install -r requirements-dev.txt

      - name: Validate Python Version
        run: |
          echo "=== Validating Python Version ==="
          PYTHON_VERSION=$(python --version 2>&1 | awk '{print $2}')
          EXPECTED_VERSION="${{ env.PYTHON_VERSION }}"
          if [[ ! "$PYTHON_VERSION" == "$EXPECTED_VERSION"* ]]; then
            echo "ERROR: Python version mismatch: expected $EXPECTED_VERSION, got $PYTHON_VERSION"
            exit 1
          fi
          echo "Python version correct: $PYTHON_VERSION"

      - name: Validate PYTHONPATH
        run: |
          echo "=== Validating PYTHONPATH ==="
          if [ -z "$PYTHONPATH" ]; then
            echo "ERROR: PYTHONPATH is not set"
            exit 1
          fi
          if [ "$PYTHONPATH" != "${{ github.workspace }}" ]; then
            echo "ERROR: PYTHONPATH mismatch"
            echo "Expected: ${{ github.workspace }}"
            echo "Actual: $PYTHONPATH"
            exit 1
          fi
          echo "PYTHONPATH: $PYTHONPATH"

      - name: Verify build
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          python -c "import app; print('PASS: All modules import successfully')"

      - name: Validate Import Resolution
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Validating Import Resolution ==="
          python3 << 'PYEOF'
          import sys
          import os

          sys.path.insert(0, os.getcwd())

          critical_imports = [
              'app',
              'app.core',
              'app.core.location_normalizer',
              'app.core.regions',
              'connectors',
          ]

          errors = 0
          for module in critical_imports:
              try:
                  __import__(module)
                  print(f"PASS: {module}")
              except ImportError as e:
                  print(f"FAIL: {module} - {e}")
                  errors += 1

          if errors > 0:
              sys.exit(1)
          PYEOF

  test:
    name: Tests
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Pre-cleanup disk
        run: |
          echo "=== Pre-cleanup Disk Usage ==="
          df -h | head -2
          find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
          find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
            app/backend/requirements.txt

      - name: Validate Requirements Files Exist
        run: |
          echo "=== Validating Requirements Files ==="
          for req_file in requirements.txt requirements-dev.txt app/backend/requirements.txt; do
            if [ ! -f "$req_file" ]; then
              echo "ERROR: Missing requirements file: $req_file"
              exit 1
            fi
            echo "Found: $req_file"
          done

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r app/backend/requirements.txt
          pip install -r requirements-dev.txt

      - name: Validate Test Directory
        run: |
          echo "=== Validating Test Directory ==="
          if [ ! -d "tests" ]; then
            echo "ERROR: tests/ directory not found"
            exit 1
          fi
          TEST_COUNT=$(find tests -name "test_*.py" | wc -l)
          if [ "$TEST_COUNT" -eq 0 ]; then
            echo "ERROR: No test files found in tests/"
            exit 1
          fi
          echo "Found $TEST_COUNT test files"

      - name: Validate Test Discovery
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Validating Test Discovery ==="
          if ! python -m pytest --collect-only -q tests/ 2>&1; then
            echo "ERROR: pytest cannot discover tests"
            exit 1
          fi
          TEST_COUNT=$(python -m pytest --collect-only -q tests/ 2>/dev/null | grep -c "test session starts" || echo "0")
          if [ "$TEST_COUNT" -eq "0" ]; then
            echo "ERROR: No tests discovered"
            exit 1
          fi
          echo "Test discovery successful"

      - name: Run tests
        timeout-minutes: 30
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          pytest tests/ --cov=app --cov=hbc --cov-report=term-missing --cov-report=xml -v --maxfail=5 --tb=short -n auto
        continue-on-error: false

      - name: Run invariant enforcement tests
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Running Invariant Enforcement Tests ==="
          pytest tests/test_invariant_enforcement.py -v --tb=short || (echo "ERROR: Invariant enforcement tests failed" && exit 1)

      - name: Run contract enforcement tests
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Running Contract Enforcement Tests ==="
          pytest tests/test_contract_enforcement.py -v --tb=short || (echo "ERROR: Contract enforcement tests failed" && exit 1)

      - name: Run version evolution tests
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Running Version Evolution Tests ==="
          pytest tests/test_version_evolution.py -v --tb=short || (echo "ERROR: Version evolution tests failed" && exit 1)

      - name: Validate Test Coverage Threshold
        if: matrix.python-version == '3.12'
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Validating Test Coverage ==="
          coverage report --fail-under=70 || echo "WARNING: Coverage below 70% (not blocking)"

      - name: Validate No Skipped Tests
        if: always()
        env:
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          echo "=== Validating No Skipped Tests ==="
          SKIPPED=$(pytest tests/ --collect-only -q 2>/dev/null | grep -c "skipped" || echo "0")
          if [ "$SKIPPED" -gt "0" ]; then
            echo "WARNING: Found skipped tests (not blocking)"
          fi

      - name: Upload coverage
        if: matrix.python-version == '3.12'
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Post-cleanup test artifacts
        if: always()
        run: |
          echo "=== Post-cleanup Disk Usage ==="
          df -h | head -2
          find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
          find . -type d -name "htmlcov" -exec rm -rf {} + 2>/dev/null || true
          find . -type f -name ".coverage.*" -delete 2>/dev/null || true

  emoji-check:
    name: check-no-emoji
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate Script Exists
        run: |
          if [ ! -f ".github/scripts/check_no_emoji.py" ]; then
            echo "ERROR: check_no_emoji.py not found"
            exit 1
          fi

      - name: Check for emojis in Markdown and code files
        run: python3 .github/scripts/check_no_emoji.py

  docs-link-check:
    name: Docs link check
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate Script Exists
        run: |
          if [ ! -f ".github/scripts/validate_docs_links.py" ]; then
            echo "ERROR: validate_docs_links.py not found"
            exit 1
          fi

      - name: Validate internal markdown links
        run: python3 .github/scripts/validate_docs_links.py

      - name: Validate external markdown links
        run: python3 .github/scripts/validate_external_links.py

  lint-format:
    name: Lint & Format
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Pre-cleanup disk
        run: |
          echo "=== Pre-cleanup Disk Usage ==="
          df -h | head -2
          find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
          find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
            app/backend/requirements.txt

      - name: Validate Requirements Files Exist
        run: |
          echo "=== Validating Requirements Files ==="
          for req_file in requirements.txt requirements-dev.txt app/backend/requirements.txt; do
            if [ ! -f "$req_file" ]; then
              echo "ERROR: Missing requirements file: $req_file"
              exit 1
            fi
            echo "Found: $req_file"
          done

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r app/backend/requirements.txt
          pip install -r requirements-dev.txt

      - name: Validate Lint Tools Installed
        run: |
          echo "=== Validating Lint Tools ==="
          if ! command -v ruff &> /dev/null; then
            echo "ERROR: ruff not installed"
            exit 1
          fi
          if ! command -v black &> /dev/null; then
            echo "ERROR: black not installed"
            exit 1
          fi
          echo "ruff and black are installed"

      - name: Ruff Lint
        run: ruff check app/ tests/ scripts/

      - name: Black Format
        run: black --check app/ tests/ scripts/

      - name: Format Lock Validation
        run: |
          echo "=== Format Lock Validation ==="
          black --check --diff app/ tests/ scripts/ > format-diff.txt || true
          if [ -s format-diff.txt ]; then
            echo "ERROR: Format drift detected. Run 'black app/ tests/ scripts/' to fix."
            cat format-diff.txt
            exit 1
          fi
          echo "PASS: No format drift detected"

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    strategy:
      fail-fast: false
      matrix:
        scan-type: [bandit, pip-audit, trivy]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r app/backend/requirements.txt
          pip install -r requirements-dev.txt

      - name: Run Bandit Security Scan
        if: matrix.scan-type == 'bandit'
        run: |
          pip install bandit[toml]
          bandit -r app/ connectors/ -f json -o bandit-report.json || true
          bandit -r app/ connectors/ -ll

      - name: Run pip-audit
        if: matrix.scan-type == 'pip-audit'
        run: |
          pip install pip-audit
          pip-audit --requirement requirements.txt --requirement requirements-dev.txt --requirement app/backend/requirements.txt --format=json --output=pip-audit-report.json || true
          pip-audit --requirement requirements.txt --requirement requirements-dev.txt --requirement app/backend/requirements.txt

      - name: Run Trivy Vulnerability Scanner
        if: matrix.scan-type == 'trivy'
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        if: matrix.scan-type == 'trivy'
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  # docker-e2e:
  #   name: Docker E2E Tests
  #   runs-on: ubuntu-latest
  #   needs: [build, test]
  #   steps:
  #     - name: Checkout
  #       uses: actions/checkout@v4
  #
  #     - name: Set up Docker Buildx
  #       uses: docker/setup-buildx-action@v3
  #
  #     - name: Run Docker E2E Test Suite
  #       run: |

  conventional-commits:
    name: Conventional Commits Validation
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate Commit Messages
        run: |
          python3 .github/scripts/validate_conventional_commits.py "$(git log --format=%B -n 1 HEAD)"

  docker-e2e:
    name: Docker E2E Smoke Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and start Docker Compose stack
        run: |
          docker compose up -d --build
          echo "Docker Compose stack started"

      - name: Wait for Docker services and verify all routes
        run: |
          echo "=== Docker Service Readiness Gates ==="

          # Wait for backend (inside container healthcheck)
          echo "Waiting for backend container healthcheck..."
          for i in {1..60}; do
            if docker compose exec -T backend curl -f http://localhost:8000/health >/dev/null 2>&1; then
              echo "  Backend container: HEALTHY (${i}s)"
              break
            fi
            if [ $i -eq 60 ]; then
              echo "ERROR: Backend container healthcheck failed after 60s"
              docker compose logs backend --tail=100
              exit 1
            fi
            sleep 1
          done

          # Verify backend accessible from host
          echo "Verifying backend accessible from host (localhost:8100)..."
          for i in {1..30}; do
            if curl -fsS http://localhost:8100/health >/dev/null 2>&1; then
              echo "  Backend host access: OK (${i}s)"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "ERROR: Backend not accessible from host after 30s"
              docker compose logs backend --tail=100
              exit 1
            fi
            sleep 1
          done

          # Wait for frontend container
          echo "Waiting for frontend container..."
          for i in {1..90}; do
            if curl -fsS http://localhost:3100/ >/dev/null 2>&1; then
              echo "  Frontend root: OK (${i}s)"
              break
            fi
            if [ $i -eq 90 ]; then
              echo "ERROR: Frontend not responding after 90s"
              docker compose logs frontend --tail=100
              exit 1
            fi
            sleep 1
          done

          # Critical: verify /forecast and /history routes (known failure points)
          echo "Verifying critical routes..."
          for route in /forecast /history; do
            http_code=$(curl -sS -o /dev/null -w "%{http_code}" "http://localhost:3100${route}")
            if [ "$http_code" = "200" ]; then
              echo "  ${route}: 200 OK"
            else
              echo "ERROR: ${route} returned HTTP ${http_code}"
              echo "Docker containers:"
              docker ps
              echo "Frontend logs:"
              docker compose logs frontend --tail=100
              exit 1
            fi
          done

          # Warm up backend with forecast generation
          echo "Warming up backend (pre-generate metrics)..."
          curl -sS http://localhost:8100/api/forecasting/regions | jq 'length' || echo "  Regions API: called"
          curl -sS -X POST http://localhost:8100/api/forecast \
            -H "Content-Type: application/json" \
            -d '{"region_id":"us_mn","region_name":"Minnesota","days_back":30,"forecast_horizon":7}' \
            | jq '.metadata.region_id' || echo "  Forecast: called"

          echo "=== All readiness gates PASSED ==="

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: app/frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: app/frontend
        run: |
          # Clean up any Docker-created files that might have permission issues
          sudo rm -rf node_modules .next || true
          npm ci

      - name: Install Playwright browsers
        working-directory: app/frontend
        run: npx playwright install chromium

      - name: Re-verify routes before Playwright (CI stability)
        run: |
          echo "=== Pre-Playwright Route Verification ==="
          # Re-check routes after npm/Playwright install (services may have restarted)
          for i in {1..30}; do
            forecast_code=$(curl -sS -o /dev/null -w "%{http_code}" "http://localhost:3100/forecast" 2>/dev/null || echo "000")
            history_code=$(curl -sS -o /dev/null -w "%{http_code}" "http://localhost:3100/history" 2>/dev/null || echo "000")

            if [ "$forecast_code" = "200" ] && [ "$history_code" = "200" ]; then
              echo "  Routes verified: /forecast=200, /history=200"
              break
            fi

            if [ $i -eq 30 ]; then
              echo "ERROR: Routes not ready after 30s (forecast=${forecast_code}, history=${history_code})"
              docker compose logs frontend --tail=50
              exit 1
            fi

            echo "  Attempt ${i}/30: forecast=${forecast_code}, history=${history_code} (waiting...)"
            sleep 1
          done
          echo "=== Routes ready for Playwright ==="

      - name: Run Docker E2E smoke tests
        working-directory: app/frontend
        env:
          PLAYWRIGHT_BASE_URL: http://localhost:3100
        run: |
          set +e
          LOG="/tmp/docker-e2e-playwright.log"

          # Print diagnostics marker BEFORE tests (always captured)
          echo "=== DOCKER_E2E_DIAGNOSTICS_PRE ===" | tee "$LOG"
          echo "Environment:" | tee -a "$LOG"
          echo "  PLAYWRIGHT_BASE_URL: ${PLAYWRIGHT_BASE_URL}" | tee -a "$LOG"
          echo "  PWD: $(pwd)" | tee -a "$LOG"
          echo "Docker containers:" | tee -a "$LOG"
          docker ps | tee -a "$LOG"
          echo "Backend health:" | tee -a "$LOG"
          curl -sS http://localhost:8100/health | tee -a "$LOG" || echo "  [FAIL] Backend not responding" | tee -a "$LOG"
          echo "Frontend routes:" | tee -a "$LOG"
          for route in / /forecast /history; do
            http_code=$(curl -sS -o /dev/null -w "%{http_code}" "http://localhost:3100${route}")
            echo "  ${route}: HTTP ${http_code}" | tee -a "$LOG"
          done
          echo "Regions API:" | tee -a "$LOG"
          curl -sS http://localhost:8100/api/forecasting/regions | jq -r 'length' | tee -a "$LOG" || echo "  [FAIL] Regions API error" | tee -a "$LOG"
          echo "=== Starting Playwright tests ===" | tee -a "$LOG"

          npx playwright test e2e/forecast.smoke.spec.ts e2e/history.smoke.spec.ts --reporter=line,html 2>&1 | tee -a "$LOG"
          test_exit_code=${PIPESTATUS[0]}

          echo "=== DOCKER_E2E_DIAGNOSTICS_POST ===" | tee -a "$LOG"
          echo "Test exit code: ${test_exit_code}" | tee -a "$LOG"
          echo "Docker containers (after tests):" | tee -a "$LOG"
          docker ps | tee -a "$LOG"

          if [ "$test_exit_code" -ne 0 ]; then
            echo "Extracting failure summary..." | tee -a "$LOG"
            summary="$(grep -nE 'FAIL|Error:|Timeout|expect\(|net::|page\.goto|strict mode|locator' "$LOG" | head -n 40 || true)"

            diag_pre="$(awk '/DOCKER_E2E_DIAGNOSTICS_PRE/,/Starting Playwright tests/' "$LOG" || true)"

            if [ -n "$diag_pre" ]; then
              summary="${summary}\n\n=== PRE-TEST DIAGNOSTICS ===\n${diag_pre}"
            else
              python3 -c "print('::error title=DIAGNOSTICS_MARKER_NOT_FOUND::DOCKER_E2E_DIAGNOSTICS_PRE not found')"
            fi

            export SUMMARY="$summary"
            python3 -c "import os; s=os.environ.get('SUMMARY',''); print('::error title=Docker E2E Failure::' + s.replace('%','%25').replace('\n','%0A').replace('\r','%0D'))"
          fi

          exit "$test_exit_code"

      - name: Capture final diagnostics
        if: always()
        run: |
          echo "=== FINAL DIAGNOSTICS (always runs) ==="
          echo "Docker containers final state:"
          docker ps -a
          echo ""
          echo "Backend logs (last 100 lines):"
          docker compose logs backend --tail=100 || echo "Could not get backend logs"
          echo ""
          echo "Frontend logs (last 100 lines):"
          docker compose logs frontend --tail=100 || echo "Could not get frontend logs"
          echo ""
          echo "Final route checks:"
          for route in / /forecast /history; do
            http_code=$(curl -sS -o /dev/null -w "%{http_code}" "http://localhost:3100${route}" 2>/dev/null || echo "FAIL")
            echo "  http://localhost:3100${route}: ${http_code}"
          done

      - name: Ensure test-results directory exists
        if: always()
        working-directory: app/frontend
        run: |
          mkdir -p test-results
          # Create a placeholder file to ensure directory is not empty for artifact upload
          echo "# Test results directory" > test-results/README.md
          echo "# Playwright outputs traces and screenshots here on failures/retries" >> test-results/README.md

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: docker-e2e-playwright-report
          path: app/frontend/playwright-report/
          retention-days: 7
          if-no-files-found: warn

      - name: Upload test-results artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: docker-e2e-test-results
          path: app/frontend/test-results/
          retention-days: 7
          if-no-files-found: warn

      - name: Cleanup Docker Compose
        if: always()
        run: |
          docker compose down -v
